{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords\n",
    "from string import digits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(s):\n",
    "    s = s.lower()\n",
    "    data = re.sub(r'[^\\x00-\\x7F]+', ' ', s)\n",
    "    final_str = data.translate(None, string.punctuation)\n",
    "    filter_str = final_str.translate(None, digits)\n",
    "    nltk_tokens = nltk.word_tokenize(filter_str)\n",
    "    #Next find the roots of the word\n",
    "    str_= ''\n",
    "    for w in nltk_tokens:\n",
    "\n",
    "        if w not in stopwords.words('english'):\n",
    "            str_ += ' '  + (lemmatizer.lemmatize(w))\n",
    "    \n",
    "    return str_.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/prashant/Downloads/c3cc8568-0-dataset/train.csv')\n",
    "df_train['tag'] = 'train'\n",
    "print df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.isnull().sum()\n",
    "df['Complaint-reason'] = df['Complaint-reason'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.isnull().sum()\n",
    "df['Consumer-complaint-summary'] = df['Consumer-complaint-summary'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['Consumer-complaint-summary'] = df['Consumer-complaint-summary'].map(lambda x : re.sub(\"x+\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"merge\"] = df[\"Consumer-complaint-summary\"].map(str)+ \" \" + df[\"Complaint-reason\"]\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/prashant/preprocess_brain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(model,all_data):\n",
    "    vector_sen = []\n",
    "    for d in all_data:\n",
    "        single_sen_vec = []\n",
    "        words = d.split(' ')\n",
    "        for w in words:\n",
    "            try:\n",
    "                \n",
    "                get_word_vec = model[w]\n",
    "            except:\n",
    "                get_word_vec =np.zeros(300)\n",
    "                pass\n",
    "            single_sen_vec.append(get_word_vec)\n",
    "        v = np.array(single_sen_vec).mean(axis=0)\n",
    "        vector_sen.append(v)\n",
    "    return vector_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 2196016  words loaded!\n"
     ]
    }
   ],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model\n",
    "\n",
    "model = loadGloveModel('/home/prashant/Downloads/kagsa/data/glove.840B.300d.txt')\n",
    "#vocab = model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = list(df['merge'])\n",
    "# vectorizer = TfidfVectorizer(min_df=15,max_df=100)\n",
    "# # tokenize and build vocab\n",
    "# vectorizer.fit(text)\n",
    "vector = get_vector(model,list(df['merge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        seterus inc po un fau rapport aupr de principa...\n",
       "1           la requ te en faillite n  du chapitre  po e...\n",
       "2        el   estaba preparando el vuelo de regreso  ve...\n",
       "3        loan paid    year moved va moved     month pay...\n",
       "4        jai obtenu un compte de cr dit de soins pour  ...\n",
       "5        owner original mortgage filed bankruptcy later...\n",
       "6        jai victime dune fraude didentit et jai contac...\n",
       "7        je suis en train de faire faillite et par con ...\n",
       "8        una agencia de cobranza hizo adulterar de que ...\n",
       "9        le   jai u une r ponse deperian indiquant que ...\n",
       "10       mortgage provider united wholesale mortgage ho...\n",
       "11       boyfriend bought  sofa year pay without intere...\n",
       "12       le    environ  heures j ai v rifi mon dossier ...\n",
       "13       account settled closed must balance zero credi...\n",
       "14          open lease  dba  kia    first person lease ...\n",
       "15       scheduled full time payment online banking epi...\n",
       "16       llamado esta compa muchas veces para intentar ...\n",
       "17       todav veo una deuda con coast professional en ...\n",
       "18       never called received written notice ant debt ...\n",
       "19       cuando disput con la agencias de cr dito solo ...\n",
       "20       use gap visa card issued ge capital retail ban...\n",
       "21       equifa publi me donn e via de syst me non curi...\n",
       "22       mortgage loan transferred  caliber home loan  ...\n",
       "23       tengo menos de de retraso en mi pago program u...\n",
       "24          pulled equifa credit report noticed   accou...\n",
       "25       surprised reviewed credit report found late pa...\n",
       "26       abr una cuenta de ahorros cheque para j venes ...\n",
       "27        account date paying lot time every month time...\n",
       "28       transunion computer failure several query dele...\n",
       "29       debt wife charge call husband  called asked le...\n",
       "                               ...                        \n",
       "43236    husband  best keep bank account region bank co...\n",
       "43237    landlord applied approved short sale va    mor...\n",
       "43238    started new loan wilshire consumer credit   pa...\n",
       "43239    je suis inscrit pour une carte de cr dit sans ...\n",
       "43240    jai po une plainte aupr de cfpb et je devais p...\n",
       "43241    jai po une plainte indiquant que le informatio...\n",
       "43242    sent    letter validation creditor inform coll...\n",
       "43243    small studio   illinois trust small social sec...\n",
       "43244    trying divide plot land located   minnesota ap...\n",
       "43245     submitted documentation loan modification    ...\n",
       "43246    skip tracing various place collector violation...\n",
       "43247     complaint competent action taken corporate la...\n",
       "43248     alias  show   eviction show twice name recent...\n",
       "43249    joseph r harrison company emphasizes attorney ...\n",
       "43250    process selling house notified pnc payment day...\n",
       "43251    american epress card macys fraud charge totali...\n",
       "43252    cette dette du cr ancier initial    supprim e ...\n",
       "43253    debt eight year old shown legal obligation pay...\n",
       "43254    collector adopted administer delete call order...\n",
       "43255    mortgage greentree ditech make short sale dela...\n",
       "43256    started making etra principle payment mortgage...\n",
       "43257    compr un par de gafas para   utilizando una pr...\n",
       "43258    il entrent en jugement contre moi et demandent...\n",
       "43259    bank america ha iniciado una acci n de ejecuci...\n",
       "43260    problem eperian continue list closed account m...\n",
       "43261    jai une demande non autoris e de donn e factue...\n",
       "43262    called company want hear debt mine repeatedly ...\n",
       "43263    el prestamista le proporcion al cliente ni nue...\n",
       "43264      mortgage transferred shellpoint mortgage ser...\n",
       "43265    letter related account  claim owe formal notic...\n",
       "Name: merge, Length: 43266, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # encode document\n",
    "# vector = vectorizer.transform(text)\n",
    "# # summarize encoded vector\n",
    "# print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.DataFrame(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df['tag'] = list(df['tag'])\n",
    "vec_df['Complaint-Status'] = list(df['Complaint-Status'])\n",
    "#vec_df['Transaction-Type'] = list(df['Transaction-Type'])\n",
    "vec_df['Complaint-ID'] = list(df['Complaint-ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (vec_df['Complaint-Status'])\n",
    "x_train = vec_df.drop(['Complaint-Status','Complaint-ID','tag'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43266,)\n",
      "(43266, 5)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape\n",
    "y_train_one_hot = pd.get_dummies(y_train,prefix=['Complaint-Status'])\n",
    "print y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('/home/prashant/preprocess_brain.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train_internal, y_test_internal = train_test_split(x_train,y_train ,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rm = rf.fit(X_train, y_train_internal)\n",
    "pred_internal = rm.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805785281135934"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.f1_score(pred_internal,y_test_internal,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
