{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords\n",
    "from string import digits\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(s):\n",
    "    s = s.lower()\n",
    "    data = re.sub(r'[^\\x00-\\x7F]+', ' ', s)\n",
    "    final_str = data.translate(None, string.punctuation)\n",
    "    filter_str = final_str.translate(None, digits)\n",
    "    nltk_tokens = nltk.word_tokenize(filter_str)\n",
    "    #Next find the roots of the word\n",
    "    str_= ''\n",
    "    for w in nltk_tokens:\n",
    "\n",
    "        if w not in stopwords.words('english'):\n",
    "            str_ += ' '  + (lemmatizer.lemmatize(w))\n",
    "    \n",
    "    return str_.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18543, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/home/prashant/Downloads/c3cc8568-0-dataset/train.csv')\n",
    "df_train.head(3)\n",
    "df_test = pd.read_csv('/home/prashant/Downloads/c3cc8568-0-dataset/test.csv') \n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important columns\n",
    "#TT\n",
    "#Complaint-reason\n",
    "#Complaint-Status\n",
    "#Consumer-complaint-summary\n",
    "#list(df_train['Consumer-complaint-summary'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train[['Transaction-Type','Complaint-reason','Complaint-Status',\\\n",
    "               'Consumer-complaint-summary']]\n",
    "df.shape\n",
    "df.columns = ['Transaction_Type','Complaint_reason','Complaint_Status','Consumer_complaint_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_test[['Transaction-Type','Complaint-reason',\\\n",
    "               'Consumer-complaint-summary']]\n",
    "df_t.columns = ['Transaction_Type','Complaint_reason','Consumer_complaint_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ---done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df['Complaint_reason'] = df['Complaint_reason'].apply(preprocess_data)\n",
    "print 'train ---done'\n",
    "df_t['Complaint_reason'] = df_t['Complaint_reason'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_Type</th>\n",
       "      <th>Complaint_reason</th>\n",
       "      <th>Complaint_Status</th>\n",
       "      <th>Consumer_complaint_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>loan servicing payment escrow account</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Seterus, Inc a déposé un faux rapport auprès d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>incorrect information credit report</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>XX / XX / XXXX La requête en faillite n ° XXXX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction_Type                       Complaint_reason  \\\n",
       "0          Mortgage  loan servicing payment escrow account   \n",
       "1  Credit reporting    incorrect information credit report   \n",
       "\n",
       "                  Complaint_Status  \\\n",
       "0          Closed with explanation   \n",
       "1  Closed with non-monetary relief   \n",
       "\n",
       "                          Consumer_complaint_summary  \n",
       "0  Seterus, Inc a déposé un faux rapport auprès d...  \n",
       "1  XX / XX / XXXX La requête en faillite n ° XXXX...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['Transaction_Type'] = df['Transaction_Type'].apply(preprocess_data)#.map(lambda x : x.replace(' ','_'))\n",
    "df_t['Transaction_Type'] = df_t['Transaction_Type'].apply(preprocess_data)#.map(lambda x : x.replace(' ','_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df['Consumer_complaint_summary'] = df['Consumer_complaint_summary'].apply(preprocess_data)\n",
    "print 'train-done'\n",
    "df_t['Consumer_complaint_summary'] = df_t['Consumer_complaint_summary'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['Consumer_complaint_summary'] = df['Consumer_complaint_summary'].map(lambda x : re.sub(\"x+\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_t['Consumer_complaint_summary'] = df_t['Consumer_complaint_summary'].map(lambda x : re.sub(\"x+\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df =pd.read_csv('/home/prashant/Downloads/c3cc8568-0-dataset/pre-proces.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[\"merge\"] =  df[\"Consumer_complaint_summary\"]+ \" \"+\\\n",
    "df[\"Complaint_reason\"]\n",
    "#df[\"Consumer_complaint_summary\"].map(str)+ \" \" +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['language'] = df['merge'].apply(lambda x:detect(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dta = df[df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27733, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_Type</th>\n",
       "      <th>Complaint_reason</th>\n",
       "      <th>Complaint_Status</th>\n",
       "      <th>Consumer_complaint_summary</th>\n",
       "      <th>merge</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt collection</td>\n",
       "      <td>contd attempt collect debt owed</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>loan paid    year moved va moved     month pay...</td>\n",
       "      <td>loan paid    year moved va moved     month pay...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mortgage</td>\n",
       "      <td>loan modificationcollectionforeclosure</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>owner original mortgage filed bankruptcy later...</td>\n",
       "      <td>owner original mortgage filed bankruptcy later...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mortgage</td>\n",
       "      <td>loan servicing payment escrow account</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>mortgage provider united wholesale mortgage ho...</td>\n",
       "      <td>mortgage provider united wholesale mortgage ho...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit card</td>\n",
       "      <td>credit card protection debt protection</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>boyfriend bought  sofa year pay without intere...</td>\n",
       "      <td>boyfriend bought  sofa year pay without intere...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>credit reporting</td>\n",
       "      <td>incorrect information credit report</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>account settled closed must balance zero credi...</td>\n",
       "      <td>account settled closed must balance zero credi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Transaction_Type                        Complaint_reason  \\\n",
       "3    debt collection         contd attempt collect debt owed   \n",
       "5           mortgage  loan modificationcollectionforeclosure   \n",
       "10          mortgage   loan servicing payment escrow account   \n",
       "11       credit card  credit card protection debt protection   \n",
       "13  credit reporting     incorrect information credit report   \n",
       "\n",
       "           Complaint_Status  \\\n",
       "3   Closed with explanation   \n",
       "5   Closed with explanation   \n",
       "10  Closed with explanation   \n",
       "11  Closed with explanation   \n",
       "13  Closed with explanation   \n",
       "\n",
       "                           Consumer_complaint_summary  \\\n",
       "3   loan paid    year moved va moved     month pay...   \n",
       "5   owner original mortgage filed bankruptcy later...   \n",
       "10  mortgage provider united wholesale mortgage ho...   \n",
       "11  boyfriend bought  sofa year pay without intere...   \n",
       "13  account settled closed must balance zero credi...   \n",
       "\n",
       "                                                merge language  \n",
       "3   loan paid    year moved va moved     month pay...       en  \n",
       "5   owner original mortgage filed bankruptcy later...       en  \n",
       "10  mortgage provider united wholesale mortgage ho...       en  \n",
       "11  boyfriend bought  sofa year pay without intere...       en  \n",
       "13  account settled closed must balance zero credi...       en  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/prashant/.local/lib/python2.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# # Remove Missing values\n",
    "# # Add a column encoding the product as an integer\n",
    "\n",
    "# from io import StringIO\n",
    "# col = ['Complaint_Status', 'Complaint_reason']\n",
    "# df = df[col]\n",
    "# df = df[pd.notnull(df['Complaint_reason'])]\n",
    "# df.columns = ['Complaint_Status', 'Complaint_reason']\n",
    "# df['category_id'] = df['Complaint_Status'].factorize()[0]\n",
    "# category_id_df = df[['Complaint_Status', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "# category_to_id = dict(category_id_df.values)\n",
    "# id_to_category = dict(category_id_df[['category_id', 'Complaint_Status']].values)\n",
    "# df.head()\n",
    "#df_t['Consumer_complaint_summary'] = df_t['Consumer_complaint_summary'].map(lambda x : re.sub(\"x+\",\"\",x))\n",
    "df_t[\"merge\"] = \\\n",
    "df_t[\"Transaction_Type\"]+\" \" + df_t[\"Complaint_reason\"]\n",
    "\n",
    "df_t['language'] = df_t['merge'].apply(lambda x:detect(str(x)))\n",
    "clean_dta_tst = df_t[df_t['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_merged_text = ' '.join(list(clean_dta['merge']))\n",
    "# all_merged_text_tst = ' '.join(list(clean_dta_tst['merge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk import word_tokenize \n",
    "# from nltk.util import ngrams\n",
    "# tokenized = all_merged_text.split()\n",
    "\n",
    "# # and get a list of all the bi-grams\n",
    "# esBigrams = ngrams(tokenized, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# esBigramFreq = collections.Counter(esBigrams)\n",
    "\n",
    "# # what are the ten most popular ngrams in this Spanish corpus?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_bg = set(map(lambda x : x[0],esBigramFreq.most_common(500)))\n",
    "# most_common_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup = set(most_common_bg)  # {('let', 'us'), ('as', 'soon')}\n",
    "# final_merge_text = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     query = df['merge'][i].split(' ')\n",
    "#     answer = []\n",
    "#     q_iter = iter(range(len(query)))\n",
    "#     for idx in q_iter:\n",
    "#         answer.append(query[idx])\n",
    "#         if idx < (len(query) - 1) and (query[idx], query[idx+1]) in lookup:\n",
    "#             answer[-1] += query[idx+1]\n",
    "#             next(q_iter)\n",
    "#             # if you don't want to skip over consumed \n",
    "#             # second bi-gram elements and keep \n",
    "#             # len(query) == len(answer), don't advance \n",
    "#             # the iterator here, which also means you\n",
    "#             # don't have to create the iterator in outer scope\n",
    "\n",
    "#     final_merge_text.append(' '.join(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_text = []\n",
    "# for i in range(df_t.shape[0]):\n",
    "#     query = df['merge'][i].split(' ')\n",
    "#     answer = []\n",
    "#     q_iter = iter(range(len(query)))\n",
    "#     for idx in q_iter:\n",
    "#         answer.append(query[idx])\n",
    "#         if idx < (len(query) - 1) and (query[idx], query[idx+1]) in lookup:\n",
    "#             answer[-1] += query[idx+1]\n",
    "#             next(q_iter)\n",
    "#             # if you don't want to skip over consumed \n",
    "#             # second bi-gram elements and keep \n",
    "#             # len(query) == len(answer), don't advance \n",
    "#             # the iterator here, which also means you\n",
    "#             # don't have to create the iterator in outer scope\n",
    "\n",
    "#     testing_text.append(' '.join(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure(figsize=(8,6))\n",
    "# df.groupby('Transaction_Type').Complaint_Status.count().plot.bar(ylim=0)\n",
    "# plt.show()\n",
    "all_text  = []\n",
    "all_text = list(df['merge']) +list(df_t['merge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.float64'>, encoding='latin-1', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True,use_idf=True, min_df=10, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "tfidf.fit(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43266, 67458)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tfidf.transform(df['merge'])\n",
    "labels = df.Complaint_Status\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18543, 67458)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_t = tfidf.transform(df_t['merge'])\n",
    "\n",
    "features_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use 'sklearn.feature_selection.chi2' to find the terms that are the most correlated with each of the products\n",
    "\n",
    "# from sklearn.feature_selection import chi2\n",
    "# import numpy as np\n",
    "# N = 2\n",
    "# for Product, category_id in sorted(category_to_id.items()):\n",
    "#     features_chi2 = chi2(features, labels == category_id)\n",
    "#     indices = np.argsort(features_chi2[0])\n",
    "#     feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "#     unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "#     bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "#     print(\"--> '{}':\".format(Product))\n",
    "#     print(\"  . Most Correlated Unigrams are :\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "#     print(\"  . Most Correlated Bigrams are :\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer()\n",
    "# data = count_vect.fit_transform(df['Complaint_reason'])\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# comp_data = tfidf_transformer.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# text = list(df['Complaint_reason'])\n",
    "\n",
    "\n",
    "# vectorizer = TfidfVectorizer(min_df=5)\n",
    "\n",
    "# # tokenize and build vocab\n",
    "# vectorizer.fit(text)\n",
    "\n",
    "# fet = df['Complaint_reason']\n",
    "# # encode document\n",
    "# vector_cr = vectorizer.transform(fet)\n",
    "# # summarize encoded vector\n",
    "# print(vector_cr.shape)\n",
    "# #print(vector.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state = 0)\n",
    "clf = LinearSVC().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/bbc/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8392597962523045"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_internal = clf.predict(X_test)\n",
    "import sklearn\n",
    "sklearn.metrics.f1_score(pred_internal,y_test,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43266, 67458)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['Complaint_Status']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-152f672516bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[0mCV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "models = [\n",
    "    LogisticRegression()\n",
    "\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='f1_weighted', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "        print (model_name, fold_idx, accuracy)\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7646 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = list(df_test['Complaint-ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(features_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(id_,columns=['Complaint-ID'])\n",
    "result['Complaint-Status'] = (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/home/prashant/Downloads/c3cc8568-0-dataset/svm_l3-testing.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
